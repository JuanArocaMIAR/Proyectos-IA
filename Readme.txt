** Proyecto de Clasificaci贸n de Im谩genes con Redes Neuronales Convolucionales (CNNs) **

**Descripci贸n del Proyecto:**

Recientemente, he completado un proyecto emocionante que se centra en la clasificaci贸n de im谩genes de plantas mediante el uso de redes neuronales convolucionales (CNNs). Este proyecto incluy贸 la comparaci贸n de dos estrategias distintas para abordar un problema de clasificaci贸n de 12 tipos diferentes de plantas. A continuaci贸n, se detallan las etapas del proyecto y los resultados obtenidos.

** Pipeline de Desarrollo:**

1. **Carga e Inspecci贸n del Dataset:**
   - Importaci贸n y exploraci贸n inicial del dataset para comprender mejor sus caracter铆sticas y estructura.

2. **Acondicionamiento de los Datos:**
   - Aplicaci贸n de t茅cnicas de preprocesamiento, incluyendo normalizaci贸n y data augmentation, para mejorar la calidad del entrenamiento y la generalizaci贸n del modelo.

3. **Desarrollo y Entrenamiento del Modelo:**
   - Dise帽o de una red neuronal convolucional desde cero y comparaci贸n de su rendimiento con varios modelos preentrenados utilizando t茅cnicas de transfer learning.

4. **Evaluaci贸n y Monitorizaci贸n:**
   - Monitoreo de las curvas de aprendizaje y ajuste de los hiperpar谩metros para optimizar el rendimiento del modelo.

** Estrategia 1: Entrenamiento desde Cero**

- En esta estrategia, dise帽茅 y entren茅 una red neuronal profunda desde cero. Utilic茅 t茅cnicas avanzadas de regularizaci贸n, como dropout, batch normalization y weight regularization, logrando una precisi贸n competitiva en la clasificaci贸n de las im谩genes.

** Estrategia 2: Transfer Learning con Redes Preentrenadas**

- Implement茅 transfer learning utilizando modelos preentrenados como VGG16, ResNet50V2 y MobileNetV2. Tras comparar estas arquitecturas, el modelo ajustado con fine-tuning sobre MobileNetV2 mostr贸 la mayor precisi贸n, superando al modelo entrenado desde cero.

** Resultados y Conclusiones:**

- La estrategia de transfer learning demostr贸 ser m谩s efectiva, alcanzando una mayor precisi贸n con un tiempo de entrenamiento significativamente menor. Este hallazgo subraya la potencia de utilizar modelos preentrenados cuando los recursos computacionales y el tiempo son limitados.

** Herramientas y Tecnolog铆as Utilizadas:**

- Utilic茅 TensorFlow, Keras, Scikit-learn y Seaborn para todo el flujo de trabajo, desde la preparaci贸n de datos hasta la visualizaci贸n de resultados. El proyecto se ejecut贸 en Google Colab y el dataset se descarg贸 desde Kaggle.

** Visualizaci贸n de Resultados:**

- Incluyo visualizaciones clave como tablas resumen de los resultados obtenidos con las distintas arquitecturas, curvas de aprendizaje y matrices de confusi贸n, que ayudan a monitorizar el rendimiento del modelo durante el entrenamiento.

**Enlace al Repositorio:**

Puedes explorar los notebooks y el c贸digo fuente completo del proyecto en el siguiente enlace: [Proyectos de IA en GitHub](https://github.com/JuanArocaMIAR/Proyectos-IA)

**Contacto:**

Para cualquier pregunta o colaboraci贸n, no dudes en contactarme a trav茅s de juan.arocap@outlook.es o en .